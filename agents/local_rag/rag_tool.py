import logging
from typing import List, Optional, Union
import os
import argparse

from langchain_chroma import Chroma
from smolagents import Tool, CodeAgent, LiteLLMModel

from rag_database_builder import build_rag_database

# è®¾ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

from dotenv import load_dotenv
load_dotenv(override=True)

try:
    from sentence_transformers import CrossEncoder
    RERANK_AVAILABLE = True
except ImportError:
    RERANK_AVAILABLE = False
    logger.warning("sentence-transformersæœªå®‰è£…ï¼Œæ— æ³•ä½¿ç”¨rerankåŠŸèƒ½")

class LocalRetrieverTool(Tool):
    """æœ¬åœ°æ–‡æ¡£æ£€ç´¢å·¥å…·ï¼Œæ”¯æŒrerankæ¨¡å‹"""
    
    name = "local_retriever"
    description = """
    ä½¿ç”¨è¯­ä¹‰æœç´¢ä»æœ¬åœ°æ–‡æ¡£åº“ä¸­æ£€ç´¢ç›¸å…³ä¿¡æ¯ã€‚
    è¿™ä¸ªå·¥å…·å¯ä»¥æœç´¢æœ¬åœ°çš„txtã€pdfã€docxã€mdç­‰æ ¼å¼çš„æ–‡æ¡£ã€‚
    æ”¯æŒä¸­æ–‡å’Œè‹±æ–‡æ–‡æ¡£æ£€ç´¢ã€‚
    å¯é€‰æ‹©ä½¿ç”¨rerankæ¨¡å‹è¿›è¡Œç»“æœé‡æ’åºä»¥æé«˜æ£€ç´¢ç²¾åº¦ã€‚
    """
    
    inputs = {
        "query": {
            "type": "string",
            "description": "è¦æœç´¢çš„æŸ¥è¯¢å†…å®¹ã€‚åº”è¯¥ä½¿ç”¨é™ˆè¿°å¥è€Œä¸æ˜¯ç–‘é—®å¥ï¼Œä¾‹å¦‚ï¼š'æœºå™¨å­¦ä¹ æ¨¡å‹è®­ç»ƒæ–¹æ³•' è€Œä¸æ˜¯ 'å¦‚ä½•è®­ç»ƒæœºå™¨å­¦ä¹ æ¨¡å‹ï¼Ÿ'"
        },
        "top_k": {
            "type": "integer", 
            "description": "è¿”å›çš„ç›¸å…³æ–‡æ¡£æ•°é‡ï¼Œé»˜è®¤ä¸º5",
            "default": 5,
            "nullable": True
        },
        "use_rerank": {
            "type": "boolean",
            "description": "æ˜¯å¦ä½¿ç”¨rerankæ¨¡å‹è¿›è¡Œç»“æœé‡æ’åºï¼Œé»˜è®¤ä¸ºTrue",
            "default": True,
            "nullable": True
        }
    }
    output_type = "string"
    
    def __init__(
        self, 
        vector_store: Chroma, 
        rerank_model: str = "Qwen/Qwen3-Reranker-0.6B",
        rerank_top_k: int = 20,
        **kwargs
    ):
        super().__init__(**kwargs)
        self.vector_store = vector_store
        self.rerank_model_name = rerank_model
        self.rerank_top_k = rerank_top_k
        self.rerank_model = None
        
        # åˆå§‹åŒ–rerankæ¨¡å‹
        if RERANK_AVAILABLE:
            self._init_rerank_model()
    
    def _init_rerank_model(self):
        """åˆå§‹åŒ–rerankæ¨¡å‹"""
        try:
            logger.info(f"æ­£åœ¨åŠ è½½rerankæ¨¡å‹: {self.rerank_model_name}")
            self.rerank_model = CrossEncoder(self.rerank_model_name)
            logger.info("Rerankæ¨¡å‹åŠ è½½æˆåŠŸ")
        except Exception as e:
            logger.error(f"åŠ è½½rerankæ¨¡å‹å¤±è´¥: {e}")
            self.rerank_model = None
    
    def _rerank_documents(self, query: str, docs_with_scores: List[tuple]) -> List[tuple]:
        """ä½¿ç”¨rerankæ¨¡å‹å¯¹æ–‡æ¡£è¿›è¡Œé‡æ’åº"""
        if not self.rerank_model or not docs_with_scores:
            # è¿”å›æ ¼å¼ï¼š(doc, rerank_score, original_score)ï¼Œè¿™é‡Œç”¨åŸå§‹åˆ†æ•°ä½œä¸ºrerankåˆ†æ•°
            return [(doc, original_score, original_score) for doc, original_score in docs_with_scores]
        
        try:
            # é€ä¸ªå¤„ç†ä»¥é¿å…æ‰¹é‡å¤„ç†çš„paddingé—®é¢˜
            rerank_scores = []
            for doc, original_score in docs_with_scores:
                # é™åˆ¶æ–‡æ¡£é•¿åº¦é¿å…è¶…å‡ºæ¨¡å‹é™åˆ¶
                content = doc.page_content[:512]
                query_doc_pair = [query, content]
                
                try:
                    # å•ä¸ªå¤„ç†é¿å…æ‰¹é‡paddingé—®é¢˜
                    score = self.rerank_model.predict([query_doc_pair])[0]
                    rerank_scores.append(float(score))
                except Exception as e:
                    logger.warning(f"å•ä¸ªæ–‡æ¡£rerankå¤±è´¥ï¼Œä½¿ç”¨åŸå§‹åˆ†æ•°: {e}")
                    rerank_scores.append(float(original_score))
            
            # ç»„åˆåŸå§‹æ–‡æ¡£å’Œæ–°åˆ†æ•°
            reranked_docs = []
            for i, (doc, original_score) in enumerate(docs_with_scores):
                reranked_docs.append((doc, rerank_scores[i], original_score))
            
            # æŒ‰rerankåˆ†æ•°æ’åº
            reranked_docs.sort(key=lambda x: x[1], reverse=True)
            
            # è¿”å›æ ¼å¼ï¼š(doc, rerank_score, original_score)
            return reranked_docs
            
        except Exception as e:
            logger.error(f"Rerankè¿‡ç¨‹å‡ºé”™: {e}")
            # è¿”å›æ ¼å¼ï¼š(doc, rerank_score, original_score)ï¼Œä½¿ç”¨åŸå§‹åˆ†æ•°
            return [(doc, original_score, original_score) for doc, original_score in docs_with_scores]
    
    def forward(self, query: str, top_k: int = 5, use_rerank: bool = True) -> str:
        """æ‰§è¡Œæ–‡æ¡£æ£€ç´¢"""
        try:
            # ç¬¬ä¸€é˜¶æ®µï¼šç²—æ£€ç´¢
            # å¦‚æœä½¿ç”¨rerankï¼Œåˆ™æ£€ç´¢æ›´å¤šå€™é€‰æ–‡æ¡£
            initial_k = self.rerank_top_k if (use_rerank and self.rerank_model) else top_k
            
            # æ‰§è¡Œç›¸ä¼¼åº¦æœç´¢
            docs_with_scores = self.vector_store.similarity_search_with_score(query, k=initial_k)
            
            if not docs_with_scores:
                return "æ²¡æœ‰æ‰¾åˆ°ç›¸å…³æ–‡æ¡£ã€‚è¯·å°è¯•ä½¿ç”¨ä¸åŒçš„å…³é”®è¯æˆ–æ£€æŸ¥æ–‡æ¡£æ˜¯å¦å·²æ­£ç¡®åŠ è½½ã€‚"
            
            # ç¬¬äºŒé˜¶æ®µï¼šé‡æ’åºï¼ˆå¦‚æœå¯ç”¨ï¼‰
            if use_rerank and self.rerank_model:
                logger.info(f"ä½¿ç”¨rerankæ¨¡å‹é‡æ’åº {len(docs_with_scores)} ä¸ªå€™é€‰æ–‡æ¡£")
                reranked_docs = self._rerank_documents(query, docs_with_scores)
                
                # å–top_kä¸ªé‡æ’åºåçš„æ–‡æ¡£
                final_docs = reranked_docs[:top_k]
                
                # æ ¼å¼åŒ–ç»“æœï¼ˆåŒ…å«rerankä¿¡æ¯ï¼‰
                results = []
                for i, (doc, rerank_score, original_score) in enumerate(final_docs):
                    filename = doc.metadata.get('filename', 'æœªçŸ¥æ–‡ä»¶')
                    file_type = doc.metadata.get('file_type', 'æœªçŸ¥')
                    
                    results.append(f"""
===== æ–‡æ¡£ {i+1} =====
æ¥æºæ–‡ä»¶: {filename} ({file_type})
åŸå§‹ç›¸ä¼¼åº¦åˆ†æ•°: {original_score:.3f}
Rerankåˆ†æ•°: {rerank_score:.3f}
å†…å®¹: {doc.page_content.strip()}
""")
                
                return f"\nä½¿ç”¨rerankæ¨¡å‹é‡æ’åºåçš„ç›¸å…³æ–‡æ¡£ (ä»{initial_k}ä¸ªå€™é€‰ä¸­é€‰æ‹©{top_k}ä¸ª):\n" + "\n".join(results)
            
            else:
                # ä¸ä½¿ç”¨rerankï¼Œç›´æ¥è¿”å›embeddingæ£€ç´¢ç»“æœ
                final_docs = docs_with_scores[:top_k]
                
                # æ ¼å¼åŒ–ç»“æœ
                results = []
                for i, (doc, score) in enumerate(final_docs):
                    filename = doc.metadata.get('filename', 'æœªçŸ¥æ–‡ä»¶')
                    file_type = doc.metadata.get('file_type', 'æœªçŸ¥')
                    
                    results.append(f"""
===== æ–‡æ¡£ {i+1} (ç›¸ä¼¼åº¦åˆ†æ•°: {score:.3f}) =====
æ¥æºæ–‡ä»¶: {filename} ({file_type})
å†…å®¹: {doc.page_content.strip()}
""")
                
                return "\næ£€ç´¢åˆ°çš„ç›¸å…³æ–‡æ¡£:\n" + "\n".join(results)
            
        except Exception as e:
            error_msg = f"æ£€ç´¢è¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯: {str(e)}"
            logger.error(error_msg)
            return error_msg
    
    def get_database_stats(self) -> dict:
        """è·å–æ•°æ®åº“ç»Ÿè®¡ä¿¡æ¯"""
        try:
            collection = self.vector_store._collection
            count = collection.count()
            return {
                "total_documents": count,
                "database_path": self.vector_store._persist_directory,
                "collection_name": self.vector_store._collection.name,
                "rerank_model": self.rerank_model_name if self.rerank_model else "æœªåŠ è½½",
                "rerank_available": RERANK_AVAILABLE
            }
        except Exception as e:
            return {"error": str(e)}

def create_retriever_tool_from_builder(
    force_rebuild: bool = False,
    rerank_model: str = "Qwen/Qwen3-Reranker-0.6B",
    rerank_top_k: int = 20
) -> LocalRetrieverTool:
    """
    ä»æ•°æ®åº“æ„å»ºå™¨åˆ›å»ºæ£€ç´¢å·¥å…·
    
    Args:
        force_rebuild: æ˜¯å¦å¼ºåˆ¶é‡å»ºæ•°æ®åº“
        rerank_model: rerankæ¨¡å‹åç§°
        rerank_top_k: reranké˜¶æ®µçš„å€™é€‰æ–‡æ¡£æ•°é‡
    
    Returns:
        LocalRetrieverTool: æ£€ç´¢å·¥å…·å®ä¾‹
    """
    # æ„å»ºæˆ–åŠ è½½æ•°æ®åº“
    vector_store = build_rag_database(force_rebuild=force_rebuild)
    
    # åˆ›å»ºå·¥å…·
    return LocalRetrieverTool(
        vector_store, 
        rerank_model=rerank_model, 
        rerank_top_k=rerank_top_k
    )

def parse_arguments():
    """è§£æå‘½ä»¤è¡Œå‚æ•°"""
    parser = argparse.ArgumentParser(
        description="æœ¬åœ°RAGæ–‡æ¡£æ£€ç´¢ä»£ç†",
        epilog="""
ä½¿ç”¨ç¤ºä¾‹:
  python rag_tool.py "æœºå™¨å­¦ä¹ æ¨¡å‹è®­ç»ƒæ–¹æ³•"
  python rag_tool.py "ä»€ä¹ˆæ˜¯DynaSaur" --force-rebuild
  python rag_tool.py "æ·±åº¦å­¦ä¹ ä¼˜åŒ–ç®—æ³•" --max-steps 30 --verbosity 1
  python rag_tool.py "AIå‘å±•è¶‹åŠ¿" --model-id gpt-4o --max-steps 15 --no-rerank
        """,
        formatter_class=argparse.RawDescriptionHelpFormatter
    )
    parser.add_argument(
        "query",
        type=str,
        help="è¦æœç´¢çš„æŸ¥è¯¢å†…å®¹"
    )
    parser.add_argument(
        "--force-rebuild",
        action="store_true",
        help="å¼ºåˆ¶é‡å»ºå‘é‡æ•°æ®åº“"
    )
    parser.add_argument(
        "--max-steps",
        type=int,
        default=20,
        help="ä»£ç†æœ€å¤§æ‰§è¡Œæ­¥æ•° (é»˜è®¤: 20)"
    )
    parser.add_argument(
        "--verbosity",
        type=int,
        default=2,
        help="æ—¥å¿—è¯¦ç»†ç¨‹åº¦ (0-2, é»˜è®¤: 2)"
    )
    parser.add_argument(
        "--planning-interval",
        type=int,
        default=4,
        help="è§„åˆ’é—´éš”æ­¥æ•° (é»˜è®¤: 4)"
    )
    parser.add_argument(
        "--model-id",
        type=str,
        default="o3",
        help="LLMæ¨¡å‹ID (é»˜è®¤: o3ï¼Œå°†è‡ªåŠ¨æ·»åŠ  litellm_proxy/ å‰ç¼€)"
    )
    parser.add_argument(
        "--rerank-model",
        type=str,
        default="Qwen/Qwen3-Reranker-0.6B",
        help="Rerankæ¨¡å‹åç§° (é»˜è®¤: Qwen/Qwen3-Reranker-0.6Bï¼Œå¤‡é€‰: BAAI/bge-reranker-base)"
    )
    parser.add_argument(
        "--no-rerank",
        action="store_true",
        help="ç¦ç”¨rerankæ¨¡å‹"
    )
    parser.add_argument(
        "--rerank-top-k",
        type=int,
        default=20,
        help="Reranké˜¶æ®µçš„å€™é€‰æ–‡æ¡£æ•°é‡ (é»˜è®¤: 20)"
    )
    
    return parser.parse_args()

# ä½¿ç”¨ç¤ºä¾‹
if __name__ == "__main__":
    # è§£æå‘½ä»¤è¡Œå‚æ•°
    args = parse_arguments()
    
    print(f"ğŸ” æ­£åœ¨å¤„ç†æŸ¥è¯¢: {args.query}")
    print(f"ğŸ“Š å¼ºåˆ¶é‡å»ºæ•°æ®åº“: {args.force_rebuild}")
    print(f"ğŸ¤– ä½¿ç”¨æ¨¡å‹: litellm_proxy/{args.model_id}")
    print(f"ğŸ¯ Rerankæ¨¡å‹: {args.rerank_model if not args.no_rerank else 'å·²ç¦ç”¨'}")
    
    # åˆ›å»ºæ£€ç´¢å·¥å…·
    retriever_tool = create_retriever_tool_from_builder(
        force_rebuild=args.force_rebuild,
        rerank_model=args.rerank_model,
        rerank_top_k=args.rerank_top_k
    )
    
    # é…ç½®æ¨¡å‹å‚æ•°
    model_params = {
        "model_id": f"litellm_proxy/{args.model_id}",
        "max_completion_tokens": 8192,
        "api_key": os.getenv("API_KEY"),
        "base_url": os.getenv("BASE_URL")
    }
    model = LiteLLMModel(**model_params)

    # åˆ›å»ºä»£ç†
    agent = CodeAgent(
        tools=[retriever_tool],
        model=model,
        max_steps=args.max_steps,
        verbosity_level=args.verbosity,
        planning_interval=args.planning_interval,
        name="local_rag_agent",
        description=f"""
        ä¸€ä¸ªæœ¬åœ°æ–‡æ¡£æ£€ç´¢ä»£ç†ï¼Œå¯ä»¥æœç´¢æœ¬åœ°æ–‡æ¡£åº“ä¸­çš„ç›¸å…³ä¿¡æ¯ã€‚
        è¿™ä¸ªä»£ç†å¯ä»¥æœç´¢æœ¬åœ°çš„txtã€pdfã€docxã€mdç­‰æ ¼å¼çš„æ–‡æ¡£ã€‚
        æ”¯æŒä¸­æ–‡å’Œè‹±æ–‡æ–‡æ¡£æ£€ç´¢ã€‚
        {'å·²å¯ç”¨rerankæ¨¡å‹è¿›è¡Œç»“æœé‡æ’åºã€‚' if not args.no_rerank else 'æœªå¯ç”¨rerankæ¨¡å‹ã€‚'}
        """,
    )
    
    # è¿è¡Œä»£ç†å¤„ç†æŸ¥è¯¢
    print("ğŸš€ å¼€å§‹æ‰§è¡ŒæŸ¥è¯¢...")
    result = agent.run(args.query)
    print(f"âœ… æŸ¥è¯¢å®Œæˆ!")
    print(f"ğŸ“‹ ç»“æœ: {result}")