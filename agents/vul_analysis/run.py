import argparse
import os

from dotenv import load_dotenv
from vul import VulnerabilityAnalysisWorkflow
from vulnerability_validator import QualityControlConfig
from poc import POCValidator

from smolagents import (
    LiteLLMModel,
    OpenAIServerModel
)

load_dotenv(override=True)

def parse_args():
    parser = argparse.ArgumentParser(description="æ¼æ´åˆ†æå·¥ä½œæµ - ä¸‰é˜¶æ®µåˆ†æ")
    parser.add_argument(
        "vulnerability_id", 
        type=str, 
        help="æ¼æ´æ ‡è¯†ç¬¦ï¼Œå¦‚CVEç¼–å·: 'CVE-2024-1234' æˆ–æ¼æ´åç§°"
    )
    parser.add_argument("--model-id", type=str, default="gpt-5-chat")
    parser.add_argument(
        "--max-steps", 
        type=int, 
        default=30, 
        help="æ¯ä¸ªé˜¶æ®µAgentçš„æœ€å¤§æ‰§è¡Œæ­¥æ•°ï¼Œé»˜è®¤ä¸º30"
    )
    parser.add_argument(
        "--stage", 
        type=str, 
        choices=["all", "info", "analysis", "exploitation"], 
        default="all",
        help="é€‰æ‹©æ‰§è¡Œçš„é˜¶æ®µ: all(å…¨éƒ¨), info(ä¿¡æ¯æ”¶é›†), analysis(åŸå› åˆ†æ), exploitation(åˆ©ç”¨åˆ†æ)"
    )
    parser.add_argument(
        "--output-dir", 
        type=str, 
        default="output",
        help="è¾“å‡ºç›®å½•ï¼Œé»˜è®¤ä¸ºoutput"
    )

    parser.add_argument(
        "--enable-monitoring", 
        action="store_true", 
        help="å¯ç”¨Phoenixç›‘æ§"
    )
    parser.add_argument(
        "--enable-validation",
        action="store_true",
        help="å¯ç”¨è´¨é‡æ ¡éªŒï¼ˆé»˜è®¤ç¦ç”¨ï¼‰"
    )
    parser.add_argument(
        "--max-retries",
        type=int,
        default=2,
        help="æ¯ä¸ªé˜¶æ®µæœ€å¤§é‡è¯•æ¬¡æ•°ï¼Œé»˜è®¤ä¸º2"
    )
    parser.add_argument(
        "--min-score",
        type=int,
        default=75,
        help="æœ€ä½è´¨é‡åˆ†æ•°è¦æ±‚ï¼Œé»˜è®¤ä¸º75"
    )
    parser.add_argument(
        "--search-engine",
        type=str,
        default="duckduckgo",
        choices=["duckduckgo", "google"],
        help="æœç´¢å¼•æ“é€‰æ‹©ï¼Œé»˜è®¤ä¸ºduckduckgo"
    )
    parser.add_argument(
        "--poc-validate",
        action="store_true",
        help="å¯ç”¨POCéªŒè¯ï¼ˆé»˜è®¤ç¦ç”¨ï¼‰"
    )
    return parser.parse_args()

def setup_monitoring(enable_monitoring):
    """è®¾ç½®ç›‘æ§"""
    if enable_monitoring:
        try:
            from phoenix.otel import register
            from openinference.instrumentation.smolagents import SmolagentsInstrumentor
            
            print("ğŸ” å¯ç”¨Phoenixç›‘æ§ï¼ŒLLMè¾“å…¥è¾“å‡ºå°†è¢«è®°å½•...")
            register()
            SmolagentsInstrumentor().instrument()
            print("âœ… ç›‘æ§æ’æ¡©å·²å¯ç”¨")
        except ImportError as e:
            print(f"âŒ æ— æ³•å¯ç”¨ç›‘æ§åŠŸèƒ½ï¼Œç¼ºå°‘ä¾èµ–åŒ…: {e}")
            return False
    return True


def main():
    args = parse_args()
    
    # è®¾ç½®ç›‘æ§
    if not setup_monitoring(args.enable_monitoring):
        return
    
    # è®¾ç½®è´¨é‡æ§åˆ¶é…ç½®
    quality_config = QualityControlConfig()
    quality_config.enable_validation = args.enable_validation
    quality_config.max_retries = args.max_retries
    quality_config.min_score_threshold = args.min_score
    
    print(f"ğŸ¯ è´¨é‡æ§åˆ¶é…ç½®:")
    print(f"   å¯ç”¨æ ¡éªŒ: {'æ˜¯' if quality_config.enable_validation else 'å¦'}")
    if quality_config.enable_validation:
        print(f"   æœ€å¤§é‡è¯•: {quality_config.max_retries}æ¬¡")
        print(f"   æœ€ä½åˆ†æ•°: {quality_config.min_score_threshold}åˆ†")
    print(f"   POCéªŒè¯: {'æ˜¯' if args.poc_validate else 'å¦'}")
    
    # åˆ›å»ºæ¨¡å‹
    model_params = {
        "model_id": f"{args.model_id}",
        #"max_completion_tokens": 8192,
        "api_key": os.getenv("API_KEY"),
        "api_base": os.getenv("BASE_URL")
    }
    #model = LiteLLMModel(**model_params)
    model = OpenAIServerModel(**model_params)
    
    # åˆ›å»ºæ¼æ´åˆ†æå·¥ä½œæµ
    workflow = VulnerabilityAnalysisWorkflow(
        model=model,
        max_steps=args.max_steps,
        output_dir=args.output_dir,
        search_engine=args.search_engine
    )
    
    # è¿è¡Œåˆ†æ
    workflow.run_analysis(
        vulnerability_id=args.vulnerability_id,
        stage=args.stage,
        quality_config=quality_config,
        model_id=args.model_id
    )
    
    # POCéªŒè¯ï¼ˆå¦‚æœå¯ç”¨ï¼‰
    if args.poc_validate:
        print("\n" + "="*60)
        print("ğŸ§ª å¼€å§‹POCéªŒè¯")
        print("="*60)
        
        try:
            # åˆ›å»ºPOCéªŒè¯å™¨
            poc_validator = POCValidator(model=model, max_steps=args.max_steps, search_engine=args.search_engine)
            
            # æŸ¥æ‰¾æœ€ç»ˆæŠ¥å‘Šæ–‡ä»¶
            from pathlib import Path
            output_path = Path(args.output_dir) / args.vulnerability_id
            final_report_path = output_path / f"final_report_{args.vulnerability_id}.md"
            
            if final_report_path.exists():
                print(f"ğŸ“– ä½¿ç”¨æœ€ç»ˆæŠ¥å‘Šè¿›è¡ŒPOCéªŒè¯: {final_report_path}")
                success = poc_validator.validate_vulnerability(
                    report_path=str(final_report_path),
                    output_dir=str(output_path)
                )
                if success:
                    print("âœ… POCéªŒè¯å®Œæˆ")
                else:
                    print("âŒ POCéªŒè¯å¤±è´¥")
            else:
                print(f"âš ï¸ æœªæ‰¾åˆ°æœ€ç»ˆæŠ¥å‘Šæ–‡ä»¶: {final_report_path}")
                print("è¯·å…ˆå®Œæˆå®Œæ•´çš„æ¼æ´åˆ†æï¼ˆ--stage allï¼‰å†è¿›è¡ŒPOCéªŒè¯")
                
        except Exception as e:
            print(f"âŒ POCéªŒè¯è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {e}")
            import traceback
            traceback.print_exc()

if __name__ == "__main__":
    main()
