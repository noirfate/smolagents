import argparse
import os

from dotenv import load_dotenv
from vul import VulnerabilityAnalysisWorkflow
from vulnerability_validator import QualityControlConfig

from smolagents import (
    LiteLLMModel,
)

load_dotenv(override=True)

def parse_args():
    parser = argparse.ArgumentParser(description="æ¼æ´åˆ†æå·¥ä½œæµ - ä¸‰é˜¶æ®µåˆ†æ")
    parser.add_argument(
        "vulnerability_id", 
        type=str, 
        help="æ¼æ´æ ‡è¯†ç¬¦ï¼Œå¦‚CVEç¼–å·: 'CVE-2024-1234' æˆ–æ¼æ´åç§°"
    )
    parser.add_argument("--model-id", type=str, default="gpt-5-chat")
    parser.add_argument(
        "--max-steps", 
        type=int, 
        default=30, 
        help="æ¯ä¸ªé˜¶æ®µAgentçš„æœ€å¤§æ‰§è¡Œæ­¥æ•°ï¼Œé»˜è®¤ä¸º30"
    )
    parser.add_argument(
        "--stage", 
        type=str, 
        choices=["all", "info", "analysis", "exploitation"], 
        default="all",
        help="é€‰æ‹©æ‰§è¡Œçš„é˜¶æ®µ: all(å…¨éƒ¨), info(ä¿¡æ¯æ”¶é›†), analysis(åŸå› åˆ†æ), exploitation(åˆ©ç”¨åˆ†æ)"
    )
    parser.add_argument(
        "--output-dir", 
        type=str, 
        default="output",
        help="è¾“å‡ºç›®å½•ï¼Œé»˜è®¤ä¸ºoutput"
    )

    parser.add_argument(
        "--enable-monitoring", 
        action="store_true", 
        help="å¯ç”¨Phoenixç›‘æ§"
    )
    parser.add_argument(
        "--enable-validation",
        action="store_true",
        help="å¯ç”¨è´¨é‡æ ¡éªŒï¼ˆé»˜è®¤ç¦ç”¨ï¼‰"
    )
    parser.add_argument(
        "--max-retries",
        type=int,
        default=2,
        help="æ¯ä¸ªé˜¶æ®µæœ€å¤§é‡è¯•æ¬¡æ•°ï¼Œé»˜è®¤ä¸º2"
    )
    parser.add_argument(
        "--min-score",
        type=int,
        default=75,
        help="æœ€ä½è´¨é‡åˆ†æ•°è¦æ±‚ï¼Œé»˜è®¤ä¸º75"
    )
    parser.add_argument(
        "--search-engine",
        type=str,
        default="duckduckgo",
        choices=["duckduckgo", "google"],
        help="æœç´¢å¼•æ“é€‰æ‹©ï¼Œé»˜è®¤ä¸ºduckduckgo"
    )
    return parser.parse_args()

def setup_monitoring(enable_monitoring):
    """è®¾ç½®ç›‘æ§"""
    if enable_monitoring:
        try:
            from phoenix.otel import register
            from openinference.instrumentation.smolagents import SmolagentsInstrumentor
            
            print("ğŸ” å¯ç”¨Phoenixç›‘æ§ï¼ŒLLMè¾“å…¥è¾“å‡ºå°†è¢«è®°å½•...")
            register()
            SmolagentsInstrumentor().instrument()
            print("âœ… ç›‘æ§æ’æ¡©å·²å¯ç”¨")
        except ImportError as e:
            print(f"âŒ æ— æ³•å¯ç”¨ç›‘æ§åŠŸèƒ½ï¼Œç¼ºå°‘ä¾èµ–åŒ…: {e}")
            return False
    return True


def main():
    args = parse_args()
    
    # è®¾ç½®ç›‘æ§
    if not setup_monitoring(args.enable_monitoring):
        return
    
    # è®¾ç½®è´¨é‡æ§åˆ¶é…ç½®
    quality_config = QualityControlConfig()
    quality_config.enable_validation = args.enable_validation
    quality_config.max_retries = args.max_retries
    quality_config.min_score_threshold = args.min_score
    
    print(f"ğŸ¯ è´¨é‡æ§åˆ¶é…ç½®:")
    print(f"   å¯ç”¨æ ¡éªŒ: {'æ˜¯' if quality_config.enable_validation else 'å¦'}")
    if quality_config.enable_validation:
        print(f"   æœ€å¤§é‡è¯•: {quality_config.max_retries}æ¬¡")
        print(f"   æœ€ä½åˆ†æ•°: {quality_config.min_score_threshold}åˆ†")
    
    # åˆ›å»ºæ¨¡å‹
    model_params = {
        "model_id": f"litellm_proxy/{args.model_id}",
        "max_completion_tokens": 8192,
        "api_key": os.getenv("API_KEY"),
        "base_url": os.getenv("BASE_URL")
    }
    model = LiteLLMModel(**model_params)
    
    # åˆ›å»ºæ¼æ´åˆ†æå·¥ä½œæµ
    workflow = VulnerabilityAnalysisWorkflow(
        model=model,
        max_steps=args.max_steps,
        output_dir=args.output_dir,
        search_engine=args.search_engine
    )
    
    # è¿è¡Œåˆ†æ
    workflow.run_analysis(
        vulnerability_id=args.vulnerability_id,
        stage=args.stage,
        quality_config=quality_config,
        model_id=args.model_id
    )

if __name__ == "__main__":
    main()
