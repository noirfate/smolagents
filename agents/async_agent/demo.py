"""
æ™ºèƒ½å¼‚æ­¥ç³»ç»Ÿæ¼”ç¤º
å±•ç¤ºCodeAgentå¦‚ä½•åŠ¨æ€è¿›è¡Œä»»åŠ¡æ‹†è§£ã€åˆ†å‘å’Œåè°ƒ
"""

import os
import time
import random
from dotenv import load_dotenv
from smolagents import Tool, LiteLLMModel
from async_task_system import create_async_agent

# åŠ è½½ç¯å¢ƒå˜é‡
load_dotenv(override=True)

# æ¨¡æ‹Ÿä¸€äº›éœ€è¦å¼‚æ­¥å¤„ç†çš„å·¥å…·
class DataAnalysisTool(Tool):
    """æ•°æ®åˆ†æå·¥å…· - æ¨¡æ‹Ÿè€—æ—¶çš„æ•°æ®åˆ†æ"""
    
    name = "analyze_dataset"
    description = "Analyze a dataset and generate insights. This is a time-consuming operation."
    
    inputs = {
        "dataset_name": {
            "type": "string",
            "description": "Name of the dataset to analyze"
        },
        "analysis_type": {
            "type": "string",
            "description": "Type of analysis: trend, correlation, summary, prediction"
        },
        "parameters": {
            "type": "object",
            "description": "Additional analysis parameters",
            "nullable": True
        }
    }
    output_type = "string"
    
    def forward(self, dataset_name: str, analysis_type: str, parameters: dict = None) -> str:
        """æ‰§è¡Œæ•°æ®åˆ†æ"""
        print(f"ğŸ“Š Starting {analysis_type} analysis on {dataset_name}")
        
        # æ¨¡æ‹Ÿåˆ†ææ—¶é—´ï¼ˆ2-6ç§’ï¼‰
        analysis_time = random.uniform(2, 6)
        time.sleep(analysis_time)
        
        # æ¨¡æ‹Ÿåˆ†æç»“æœ
        results = {
            "trend": f"{dataset_name} shows upward trend with 15% growth rate",
            "correlation": f"Strong positive correlation (0.85) found in {dataset_name}",
            "summary": f"{dataset_name}: Mean=45.2, Std=12.8, Count=1000 records",
            "prediction": f"Forecast for {dataset_name}: 23% increase expected next quarter"
        }
        
        result = results.get(analysis_type, f"Analysis completed for {dataset_name}")
        print(f"âœ… {analysis_type} analysis completed for {dataset_name}")
        
        return f"Analysis Result ({analysis_time:.1f}s): {result}"


class ReportGeneratorTool(Tool):
    """æŠ¥å‘Šç”Ÿæˆå·¥å…· - æ¨¡æ‹ŸæŠ¥å‘Šç”Ÿæˆ"""
    
    name = "generate_report"
    description = "Generate a comprehensive report based on analysis results."
    
    inputs = {
        "report_type": {
            "type": "string",
            "description": "Type of report: summary, detailed, executive"
        },
        "data_sources": {
            "type": "array",
            "description": "List of data sources or analysis results to include"
        },
        "title": {
            "type": "string",
            "description": "Report title",
            "nullable": True
        }
    }
    output_type = "string"
    
    def forward(self, report_type: str, data_sources: list, title: str = None) -> str:
        """ç”ŸæˆæŠ¥å‘Š"""
        title = title or f"{report_type.title()} Report"
        print(f"ğŸ“ Generating {report_type} report: {title}")
        
        # æ¨¡æ‹ŸæŠ¥å‘Šç”Ÿæˆæ—¶é—´
        generation_time = random.uniform(1, 3)
        time.sleep(generation_time)
        
        report = f"""
{title}
{'='*len(title)}

Report Type: {report_type.upper()}
Generated: {time.strftime('%Y-%m-%d %H:%M:%S')}
Data Sources: {len(data_sources)} sources

Key Findings:
{chr(10).join([f"â€¢ {source}" for source in data_sources[:5]])}
{'â€¢ ...' if len(data_sources) > 5 else ''}

Recommendations:
â€¢ Implement data-driven strategies based on findings
â€¢ Continue monitoring trends for future insights
â€¢ Consider expanding analysis to additional datasets

Report generated in {generation_time:.1f} seconds.
"""
        
        print(f"âœ… Report generated: {title}")
        return report.strip()


class DatabaseQueryTool(Tool):
    """æ•°æ®åº“æŸ¥è¯¢å·¥å…· - æ¨¡æ‹Ÿæ•°æ®åº“æŸ¥è¯¢"""
    
    name = "query_database"
    description = "Execute a database query and return results."
    
    inputs = {
        "query": {
            "type": "string",
            "description": "SQL query to execute"
        },
        "database": {
            "type": "string",
            "description": "Database name"
        },
        "timeout": {
            "type": "number",
            "description": "Query timeout in seconds (default: 5)",
            "nullable": True
        }
    }
    output_type = "string"
    
    def forward(self, query: str, database: str, timeout: float = 5) -> str:
        """æ‰§è¡Œæ•°æ®åº“æŸ¥è¯¢"""
        print(f"ğŸ—„ï¸ Executing query on {database}: {query[:50]}...")
        
        # æ¨¡æ‹ŸæŸ¥è¯¢æ—¶é—´
        query_time = min(random.uniform(1, 4), timeout)
        time.sleep(query_time)
        
        # æ¨¡æ‹ŸæŸ¥è¯¢ç»“æœ
        row_count = random.randint(10, 1000)
        result = f"Query executed successfully on {database}\nRows returned: {row_count}\nExecution time: {query_time:.1f}s\nSample data: [{{'id': 1, 'value': 42}}, {{'id': 2, 'value': 38}}, ...]"
        
        print(f"âœ… Query completed on {database}")
        return result


# æ¨¡æ‹Ÿä¸€ä¸ªManaged Agent
class DataScientistAgent:
    """æ•°æ®ç§‘å­¦å®¶Agent - ä¸“é—¨å¤„ç†å¤æ‚çš„æ•°æ®ç§‘å­¦ä»»åŠ¡"""
    
    def __init__(self):
        self.name = "data_scientist"
        self.description = "Expert data scientist for advanced analytics and machine learning tasks"
    
    def __call__(self, task: str, additional_args: dict = None) -> str:
        """æ‰§è¡Œæ•°æ®ç§‘å­¦ä»»åŠ¡"""
        print(f"ğŸ”¬ Data Scientist Agent: {task}")
        
        # æ¨¡æ‹Ÿå¤æ‚çš„æ•°æ®ç§‘å­¦å·¥ä½œ
        processing_time = random.uniform(3, 8)
        time.sleep(processing_time)
        
        # ç”Ÿæˆæ¨¡æ‹Ÿç»“æœ
        result = f"""
Data Science Analysis Complete:

Task: {task}
Processing Time: {processing_time:.1f} seconds
Additional Context: {additional_args if additional_args else 'None'}

Findings:
â€¢ Applied advanced statistical methods
â€¢ Identified key patterns and anomalies  
â€¢ Generated predictive models with 87% accuracy
â€¢ Recommended optimization strategies

Technical Details:
- Algorithm: Random Forest with feature selection
- Cross-validation score: 0.89
- Feature importance: [price: 0.34, location: 0.28, time: 0.21, ...]
- Model confidence: High

Completed at: {time.strftime('%H:%M:%S')}
"""
        
        print(f"âœ… Data Science task completed")
        return result.strip()


def run_complex_scenario():
    """è¿è¡Œå¤æ‚çš„å¼‚æ­¥ä»»åŠ¡åœºæ™¯"""
    
    print("ğŸš€ Starting Async Agent Demo")
    print("="*60)
    
    # åˆ›å»ºå·¥å…·å’Œagents
    tools = [
        DataAnalysisTool(),
        ReportGeneratorTool(), 
        DatabaseQueryTool()
    ]
    
    managed_agents = [DataScientistAgent()]
    
    # åˆ›å»ºæ™ºèƒ½å¼‚æ­¥CodeAgent
    model = LiteLLMModel(
        model_id="litellm_proxy/deepseek-v3.1",
        api_key=os.getenv("API_KEY"),
        base_url=os.getenv("BASE_URL"),
        max_completion_tokens=8192
    )
    
    async_agent = create_async_agent(
        tools=tools,
        managed_agents=managed_agents,
        model=model,
        max_workers=4,
        max_steps=25  # å¢åŠ æ­¥æ•°é™åˆ¶ï¼Œå› ä¸ºå¼‚æ­¥ä»»åŠ¡éœ€è¦æ›´å¤šæ­¥éª¤
    )
    
    try:
        print("\nğŸ“‹ Available Tools:", list(async_agent.tools.keys()))
        print("ğŸ“‹ Available Agents:", [agent.name for agent in managed_agents])
        
        # åœºæ™¯1ï¼šå¤æ‚æ•°æ®åˆ†æé¡¹ç›®
        print("\n" + "="*60)
        print("ğŸ¯ Scenario 1: Complex Data Analysis Project")
        print("="*60)
        
        scenario1_task = """
æˆ‘éœ€è¦å®Œæˆä¸€ä¸ªç»¼åˆçš„æ•°æ®åˆ†æé¡¹ç›®ï¼ŒåŒ…å«ä»¥ä¸‹ä»»åŠ¡ï¼š

1. åˆ†æä¸‰ä¸ªä¸åŒçš„æ•°æ®é›†ï¼š
   - sales_2023_q1: éœ€è¦è¶‹åŠ¿åˆ†æ
   - customer_behavior: éœ€è¦å…³è”æ€§åˆ†æ  
   - market_data: éœ€è¦é¢„æµ‹åˆ†æ

2. ä»æ•°æ®åº“æŸ¥è¯¢è¡¥å……æ•°æ®ï¼š
   - æŸ¥è¯¢äº§å“è¡¨è·å–äº§å“ä¿¡æ¯
   - æŸ¥è¯¢ç”¨æˆ·è¡¨è·å–ç”¨æˆ·ç»Ÿè®¡

3. è®©æ•°æ®ç§‘å­¦å®¶è¿›è¡Œæ·±åº¦æœºå™¨å­¦ä¹ åˆ†æ

4. æœ€ç»ˆç”Ÿæˆä¸€ä¸ªæ‰§è¡Œæ‘˜è¦æŠ¥å‘Š

è¯·è®¾è®¡ä¸€ä¸ªé«˜æ•ˆçš„å¹¶è¡Œå¤„ç†æ–¹æ¡ˆæ¥å®Œæˆè¿™ä¸ªé¡¹ç›®ã€‚ä½ åº”è¯¥è¯†åˆ«å“ªäº›ä»»åŠ¡å¯ä»¥å¹¶è¡Œæ‰§è¡Œï¼Œ
åˆç†å®‰æ’ä»»åŠ¡é¡ºåºï¼Œå¹¶åœ¨é€‚å½“çš„æ—¶å€™ç­‰å¾…ä»»åŠ¡å®Œæˆã€‚
"""
        
        result1 = async_agent.run_with_async_guidance(scenario1_task)
        print(f"\nâœ… Scenario 1 Result:\n{result1}")
        
        # åœºæ™¯2ï¼šå®æ—¶ç›‘æ§å’Œå“åº”
        print("\n" + "="*60)
        print("ğŸ¯ Scenario 2: Real-time Monitoring and Response")
        print("="*60)
        
        scenario2_task = """
æˆ‘éœ€è¦å»ºç«‹ä¸€ä¸ªå®æ—¶ç›‘æ§ç³»ç»Ÿï¼Œè¦æ±‚å¦‚ä¸‹ï¼š

1. åŒæ—¶ç›‘æ§5ä¸ªä¸åŒçš„æ•°æ®æºï¼š
   - website_traffic (éœ€è¦æ‘˜è¦åˆ†æ)
   - api_performance (éœ€è¦è¶‹åŠ¿åˆ†æ)
   - user_activity (éœ€è¦å…³è”åˆ†æ)
   - system_metrics (éœ€è¦å¼‚å¸¸æ£€æµ‹)
   - business_kpi (éœ€è¦é¢„æµ‹åˆ†æ)

2. å¹¶è¡ŒæŸ¥è¯¢å†å²åŸºçº¿æ•°æ®è¿›è¡Œå¯¹æ¯”

3. å¦‚æœå‘ç°å¼‚å¸¸ï¼Œç«‹å³ç”Ÿæˆå‘Šè­¦æŠ¥å‘Š

è¯·å®ç°è¿™ä¸ªç›‘æ§ç³»ç»Ÿï¼Œç¡®ä¿æ‰€æœ‰æ•°æ®æºéƒ½èƒ½å¹¶è¡Œå¤„ç†ï¼Œ
å¹¶åœ¨æ£€æµ‹åˆ°é—®é¢˜æ—¶å¿«é€Ÿå“åº”ã€‚
"""
        
        result2 = async_agent.run_with_async_guidance(scenario2_task)
        print(f"\nâœ… Scenario 2 Result:\n{result2}")
        
        # åœºæ™¯3ï¼šæ‰¹å¤„ç†ä¼˜åŒ–
        print("\n" + "="*60)
        print("ğŸ¯ Scenario 3: Batch Processing Optimization")
        print("="*60)
        
        scenario3_task = """
æˆ‘æœ‰ä¸€ä¸ªæ‰¹å¤„ç†ä»»åŠ¡éœ€è¦ä¼˜åŒ–ï¼ŒåŒ…æ‹¬ï¼š

1. å¤„ç†10ä¸ªæ•°æ®é›†ï¼Œæ¯ä¸ªéƒ½éœ€è¦ä¸åŒç±»å‹çš„åˆ†æ
2. ä¸ºæ¯ä¸ªæ•°æ®é›†ç”Ÿæˆå•ç‹¬çš„æŠ¥å‘Š
3. æœ€åç”Ÿæˆä¸€ä¸ªæ±‡æ€»æŠ¥å‘Š

ä¼ ç»Ÿæ–¹æ³•æ˜¯ä¸²è¡Œå¤„ç†ï¼Œéœ€è¦å¾ˆé•¿æ—¶é—´ã€‚è¯·å¸®æˆ‘è®¾è®¡ä¸€ä¸ªå¹¶è¡Œå¤„ç†æ–¹æ¡ˆï¼Œ
æœ€å¤§åŒ–åˆ©ç”¨å¼‚æ­¥æ‰§è¡Œèƒ½åŠ›ï¼Œå‡å°‘æ€»ä½“å¤„ç†æ—¶é—´ã€‚

æ•°æ®é›†åˆ—è¡¨ï¼šdataset_1 åˆ° dataset_10
åˆ†æç±»å‹ï¼šäº¤æ›¿ä½¿ç”¨ trend, correlation, summary, prediction
"""
        
        result3 = async_agent.run_with_async_guidance(scenario3_task)
        print(f"\nâœ… Scenario 3 Result:\n{result3}")
        
        # æ˜¾ç¤ºæœ€ç»ˆç»Ÿè®¡
        print("\n" + "="*60)
        print("ğŸ“Š Final Statistics")
        print("="*60)
        
        stats = async_agent.task_manager.get_statistics()
        print(f"Total tasks submitted: {stats['total_submitted']}")
        print(f"Total tasks completed: {stats['total_completed']}")
        print(f"Total tasks failed: {stats['total_failed']}")
        print(f"Tasks still pending: {stats['pending']}")
        print(f"Tasks still running: {stats['running']}")
        
    except Exception as e:
        print(f"âŒ Demo error: {e}")
        import traceback
        traceback.print_exc()
        
    finally:
        async_agent.shutdown()
        print("\nğŸ‰ Demo completed!")


def run_simple_scenario():
    """è¿è¡Œç®€å•çš„æ¼”ç¤ºåœºæ™¯"""
    
    print("ğŸš€ Simple Async Agent Demo")
    print("="*40)
    
    tools = [DataAnalysisTool()]
    model = LiteLLMModel(
        model_id="litellm_proxy/deepseek-v3.1",
        api_key=os.getenv("API_KEY"),
        base_url=os.getenv("BASE_URL"),
        max_completion_tokens=8192
    )
    
    async_agent = create_async_agent(
        tools=tools,
        model=model,
        max_workers=2,
        max_steps=15
    )
    
    try:
        simple_task = """
æˆ‘éœ€è¦åˆ†æä¸¤ä¸ªæ•°æ®é›†ï¼šsales_data å’Œ customer_dataã€‚
æ¯ä¸ªéƒ½éœ€è¦è¶‹åŠ¿åˆ†æã€‚è¯·è®¾è®¡ä¸€ä¸ªå¹¶è¡Œå¤„ç†æ–¹æ¡ˆæ¥æé«˜æ•ˆç‡ã€‚
"""
        
        result = async_agent.run_with_async_guidance(simple_task)
        print(f"\nResult: {result}")
        
    finally:
        async_agent.shutdown()


if __name__ == "__main__":
    # å¯ä»¥é€‰æ‹©è¿è¡Œå¤æ‚åœºæ™¯æˆ–ç®€å•åœºæ™¯
    run_simple_scenario()
    #run_complex_scenario()
