"""
æ™ºèƒ½å¼‚æ­¥ç³»ç»Ÿæ¼”ç¤º
å±•ç¤ºCodeAgentå¦‚ä½•åŠ¨æ€è¿›è¡Œä»»åŠ¡æ‹†è§£ã€åˆ†å‘å’Œåè°ƒ
"""

import os
import time
import random
from dotenv import load_dotenv
from smolagents import Tool, LiteLLMModel
from async_task_system import create_async_agent

# åŠ è½½ç¯å¢ƒå˜é‡
load_dotenv(override=True)

# æ¨¡æ‹Ÿä¸€äº›éœ€è¦å¼‚æ­¥å¤„ç†çš„å·¥å…·
class DataAnalysisTool(Tool):
    """æ•°æ®åˆ†æå·¥å…· - æ¨¡æ‹Ÿè€—æ—¶çš„æ•°æ®åˆ†æ"""
    
    name = "analyze_dataset"
    description = "Analyze a dataset and generate insights. This is a time-consuming operation."
    
    inputs = {
        "dataset_name": {
            "type": "string",
            "description": "Name of the dataset to analyze"
        },
        "analysis_type": {
            "type": "string",
            "description": "Type of analysis: trend, correlation, summary, prediction"
        },
        "parameters": {
            "type": "object",
            "description": "Additional analysis parameters",
            "nullable": True
        }
    }
    output_type = "string"
    
    def forward(self, dataset_name: str, analysis_type: str, parameters: dict = None) -> str:
        """æ‰§è¡Œæ•°æ®åˆ†æ"""
        print(f"ğŸ“Š Starting {analysis_type} analysis on {dataset_name}")
        
        # æ¨¡æ‹Ÿåˆ†ææ—¶é—´ï¼ˆ2-6ç§’ï¼‰
        analysis_time = random.uniform(2, 6)
        time.sleep(analysis_time)
        
        # æ¨¡æ‹Ÿåˆ†æç»“æœ
        results = {
            "trend": f"{dataset_name} shows upward trend with 15% growth rate",
            "correlation": f"Strong positive correlation (0.85) found in {dataset_name}",
            "summary": f"{dataset_name}: Mean=45.2, Std=12.8, Count=1000 records",
            "prediction": f"Forecast for {dataset_name}: 23% increase expected next quarter"
        }
        
        result = results.get(analysis_type, f"Analysis completed for {dataset_name}")
        print(f"âœ… {analysis_type} analysis completed for {dataset_name}")
        
        return f"Analysis Result ({analysis_time:.1f}s): {result}"


class ReportGeneratorTool(Tool):
    """æŠ¥å‘Šç”Ÿæˆå·¥å…· - æ¨¡æ‹ŸæŠ¥å‘Šç”Ÿæˆ"""
    
    name = "generate_report"
    description = "Generate a comprehensive report based on analysis results."
    
    inputs = {
        "report_type": {
            "type": "string",
            "description": "Type of report: summary, detailed, executive"
        },
        "data_sources": {
            "type": "array",
            "description": "List of data sources or analysis results to include"
        },
        "title": {
            "type": "string",
            "description": "Report title",
            "nullable": True
        }
    }
    output_type = "string"
    
    def forward(self, report_type: str, data_sources: list, title: str = None) -> str:
        """ç”ŸæˆæŠ¥å‘Š"""
        title = title or f"{report_type.title()} Report"
        print(f"ğŸ“ Generating {report_type} report: {title}")
        
        # æ¨¡æ‹ŸæŠ¥å‘Šç”Ÿæˆæ—¶é—´
        generation_time = random.uniform(1, 3)
        time.sleep(generation_time)
        
        report = f"""
{title}
{'='*len(title)}

Report Type: {report_type.upper()}
Generated: {time.strftime('%Y-%m-%d %H:%M:%S')}
Data Sources: {len(data_sources)} sources

Key Findings:
{chr(10).join([f"â€¢ {source}" for source in data_sources[:5]])}
{'â€¢ ...' if len(data_sources) > 5 else ''}

Recommendations:
â€¢ Implement data-driven strategies based on findings
â€¢ Continue monitoring trends for future insights
â€¢ Consider expanding analysis to additional datasets

Report generated in {generation_time:.1f} seconds.
"""
        
        print(f"âœ… Report generated: {title}")
        return report.strip()


class DatabaseQueryTool(Tool):
    """æ•°æ®åº“æŸ¥è¯¢å·¥å…· - æ¨¡æ‹Ÿæ•°æ®åº“æŸ¥è¯¢"""
    
    name = "query_database"
    description = "Execute a database query and return results."
    
    inputs = {
        "query": {
            "type": "string",
            "description": "SQL query to execute"
        },
        "database": {
            "type": "string",
            "description": "Database name"
        },
        "timeout": {
            "type": "number",
            "description": "Query timeout in seconds (default: 5)",
            "nullable": True
        }
    }
    output_type = "string"
    
    def forward(self, query: str, database: str, timeout: float = 5) -> str:
        """æ‰§è¡Œæ•°æ®åº“æŸ¥è¯¢"""
        print(f"ğŸ—„ï¸ Executing query on {database}: {query[:50]}...")
        
        # æ¨¡æ‹ŸæŸ¥è¯¢æ—¶é—´
        query_time = min(random.uniform(1, 4), timeout)
        time.sleep(query_time)
        
        # æ¨¡æ‹ŸæŸ¥è¯¢ç»“æœ
        row_count = random.randint(10, 1000)
        result = f"Query executed successfully on {database}\nRows returned: {row_count}\nExecution time: {query_time:.1f}s\nSample data: [{{'id': 1, 'value': 42}}, {{'id': 2, 'value': 38}}, ...]"
        
        print(f"âœ… Query completed on {database}")
        return result


# åˆ›å»ºæ•°æ®ç§‘å­¦å®¶CodeAgentçš„å‡½æ•°
def create_data_scientist_agent(model):
    """åˆ›å»ºä¸“é—¨çš„æ•°æ®ç§‘å­¦å®¶CodeAgent"""
    from smolagents import CodeAgent
    
    data_scientist_prompt = """ä½ æ˜¯ä¸€ä½ä¸“ä¸šçš„æ•°æ®ç§‘å­¦å®¶AIåŠ©æ‰‹ï¼Œä¸“é—¨å¤„ç†å¤æ‚çš„æ•°æ®ç§‘å­¦å’Œæœºå™¨å­¦ä¹ ä»»åŠ¡ã€‚

ä½ çš„ä¸“é•¿åŒ…æ‹¬ï¼š
- æ•°æ®åˆ†æå’Œç»Ÿè®¡å»ºæ¨¡
- æœºå™¨å­¦ä¹ ç®—æ³•è®¾è®¡å’Œä¼˜åŒ–  
- é¢„æµ‹æ¨¡å‹æ„å»º
- æ•°æ®å¯è§†åŒ–
- ä¸šåŠ¡æ´å¯Ÿæå–

å½“æ”¶åˆ°ä»»åŠ¡æ—¶ï¼Œä½ éœ€è¦ï¼š
1. åˆ†æä»»åŠ¡è¦æ±‚å’Œæä¾›çš„æ•°æ®
2. é€‰æ‹©åˆé€‚çš„ç®—æ³•å’Œæ–¹æ³•
3. è¿›è¡Œæ¨¡æ‹Ÿçš„æ•°æ®å¤„ç†å’Œå»ºæ¨¡ï¼ˆä½¿ç”¨sleepæ¨¡æ‹Ÿè®¡ç®—æ—¶é—´ï¼‰
4. ç”Ÿæˆè¯¦ç»†çš„åˆ†ææŠ¥å‘Šï¼ŒåŒ…æ‹¬ï¼š
   - ä½¿ç”¨çš„æ–¹æ³•å’Œç®—æ³•
   - å…³é”®å‘ç°å’Œæ´å¯Ÿ
   - æ¨¡å‹æ€§èƒ½æŒ‡æ ‡
   - ä¸šåŠ¡å»ºè®®

æ³¨æ„ï¼š
- ä½¿ç”¨python_interpreterå·¥å…·æ‰§è¡Œ `import time; time.sleep(éšæœº3-8ç§’)` æ¥æ¨¡æ‹Ÿå¤æ‚è®¡ç®—çš„è€—æ—¶
- åœ¨sleepæœŸé—´å¯ä»¥è¾“å‡º"æ­£åœ¨è¿›è¡Œå¤æ‚çš„æœºå™¨å­¦ä¹ è®¡ç®—..."ç­‰çŠ¶æ€ä¿¡æ¯
- æä¾›å…·ä½“çš„æŠ€æœ¯ç»†èŠ‚å’Œæ•°å€¼ç»“æœï¼ˆå¯ä»¥æ¨¡æ‹Ÿåˆç†çš„æ•°å€¼ï¼‰
- ä¿æŒä¸“ä¸šçš„æ•°æ®ç§‘å­¦æœ¯è¯­å’Œåˆ†ææ€è·¯
- æœ€åç”¨final_answerè¾“å‡ºå®Œæ•´çš„åˆ†ææŠ¥å‘Š

å·¥ä½œæµç¨‹ç¤ºä¾‹ï¼š
1. é¦–å…ˆåˆ†æä»»åŠ¡å’Œæ•°æ®
2. ä½¿ç”¨python_interpreteræ‰§è¡Œ: `import time, random; processing_time = random.uniform(3, 8); print(f"å¼€å§‹å¤æ‚çš„æœºå™¨å­¦ä¹ è®¡ç®—ï¼Œé¢„è®¡éœ€è¦{processing_time:.1f}ç§’..."); time.sleep(processing_time); print("è®¡ç®—å®Œæˆï¼")`
3. ç”Ÿæˆè¯¦ç»†çš„åˆ†ææŠ¥å‘Š
"""
    
    # å¯¼å…¥sleepå·¥å…·ç”¨äºæ¨¡æ‹Ÿè®¡ç®—æ—¶é—´
    from smolagents.default_tools import PythonInterpreterTool
    
    # åˆ›å»ºæ•°æ®ç§‘å­¦å®¶CodeAgent
    data_scientist = CodeAgent(
        tools=[PythonInterpreterTool()],  # æä¾›Pythonå·¥å…·ç”¨äºè®¡ç®—å’Œsleep
        model=model,
        instructions=data_scientist_prompt,  # CodeAgentä½¿ç”¨instructionsè€Œä¸æ˜¯system_prompt
        max_steps=10,
        name="data_scientist",  # ç›´æ¥åœ¨æ„é€ å‡½æ•°ä¸­è®¾ç½®name
        description="Expert data scientist for advanced analytics and machine learning tasks"  # ç›´æ¥è®¾ç½®description
    )
    
    return data_scientist


def run_complex_scenario():
    """è¿è¡Œå¤æ‚çš„å¼‚æ­¥ä»»åŠ¡åœºæ™¯"""
    
    print("ğŸš€ Starting Async Agent Demo")
    print("="*60)
    
    # åˆ›å»ºæ¨¡å‹
    model = LiteLLMModel(
        model_id="litellm_proxy/deepseek-v3.1",
        api_key=os.getenv("API_KEY"),
        base_url=os.getenv("BASE_URL"),
        max_completion_tokens=8192
    )
    
    # åˆ›å»ºå·¥å…·å’Œagents
    tools = [
        DataAnalysisTool(),
        ReportGeneratorTool(), 
        DatabaseQueryTool()
    ]
    
    # åˆ›å»ºçœŸå®çš„æ•°æ®ç§‘å­¦å®¶CodeAgent
    data_scientist = create_data_scientist_agent(model)
    managed_agents = [data_scientist]
    
    async_agent = create_async_agent(
        tools=tools,
        managed_agents=managed_agents,
        model=model,
        max_workers=4,
        max_steps=25  # å¢åŠ æ­¥æ•°é™åˆ¶ï¼Œå› ä¸ºå¼‚æ­¥ä»»åŠ¡éœ€è¦æ›´å¤šæ­¥éª¤
    )
    
    try:
        print("\nğŸ“‹ Available Tools:", list(async_agent.tools.keys()))
        print("ğŸ“‹ Available Agents:", [agent.name for agent in managed_agents])
        
        # åœºæ™¯1ï¼šå¤æ‚æ•°æ®åˆ†æé¡¹ç›®
        print("\n" + "="*60)
        print("ğŸ¯ Scenario 1: Complex Data Analysis Project")
        print("="*60)
        
        task = """
æˆ‘éœ€è¦å®Œæˆä¸€ä¸ªç»¼åˆçš„æ•°æ®åˆ†æé¡¹ç›®ï¼ŒåŒ…å«ä»¥ä¸‹ä»»åŠ¡ï¼š

1. åˆ†æä¸‰ä¸ªä¸åŒçš„æ•°æ®é›†ï¼š
   - sales_2023_q1: éœ€è¦è¶‹åŠ¿åˆ†æ
   - customer_behavior: éœ€è¦å…³è”æ€§åˆ†æ  
   - market_data: éœ€è¦é¢„æµ‹åˆ†æ

2. ä»æ•°æ®åº“æŸ¥è¯¢è¡¥å……æ•°æ®ï¼š
   - æŸ¥è¯¢äº§å“è¡¨è·å–äº§å“ä¿¡æ¯
   - æŸ¥è¯¢ç”¨æˆ·è¡¨è·å–ç”¨æˆ·ç»Ÿè®¡

3. è®©æ•°æ®ç§‘å­¦å®¶è¿›è¡Œæ·±åº¦æœºå™¨å­¦ä¹ åˆ†æ

4. æœ€ç»ˆç”Ÿæˆä¸€ä¸ªæ‰§è¡Œæ‘˜è¦æŠ¥å‘Š

è¯·è®¾è®¡ä¸€ä¸ªé«˜æ•ˆçš„å¹¶è¡Œå¤„ç†æ–¹æ¡ˆæ¥å®Œæˆè¿™ä¸ªé¡¹ç›®ã€‚ä½ åº”è¯¥è¯†åˆ«å“ªäº›ä»»åŠ¡å¯ä»¥å¹¶è¡Œæ‰§è¡Œï¼Œ
åˆç†å®‰æ’ä»»åŠ¡é¡ºåºï¼Œå¹¶åœ¨é€‚å½“çš„æ—¶å€™ç­‰å¾…ä»»åŠ¡å®Œæˆã€‚
"""
        
        result = async_agent.run_with_async_guidance(task)
        print(f"\nâœ… Result:\n{result}")
        
    except Exception as e:
        print(f"âŒ Demo error: {e}")
        import traceback
        traceback.print_exc()
        
    finally:
        async_agent.shutdown()
        print("\nğŸ‰ Demo completed!")


def run_simple_scenario():
    """è¿è¡Œç®€å•çš„æ¼”ç¤ºåœºæ™¯"""
    
    print("ğŸš€ Simple Async Agent Demo")
    print("="*40)
    
    tools = [DataAnalysisTool()]
    model = LiteLLMModel(
        model_id="litellm_proxy/deepseek-v3.1",
        api_key=os.getenv("API_KEY"),
        base_url=os.getenv("BASE_URL"),
        max_completion_tokens=8192
    )
    
    async_agent = create_async_agent(
        tools=tools,
        model=model,
        max_workers=2,
        max_steps=15
    )
    
    try:
        simple_task = """
æˆ‘éœ€è¦åˆ†æä¸¤ä¸ªæ•°æ®é›†ï¼šsales_data å’Œ customer_dataã€‚
æ¯ä¸ªéƒ½éœ€è¦è¶‹åŠ¿åˆ†æã€‚è¯·è®¾è®¡ä¸€ä¸ªå¹¶è¡Œå¤„ç†æ–¹æ¡ˆæ¥æé«˜æ•ˆç‡ã€‚
"""
        
        result = async_agent.run_with_async_guidance(simple_task)
        print(f"\nResult: {result}")
        
    finally:
        async_agent.shutdown()


if __name__ == "__main__":
    # å¯ä»¥é€‰æ‹©è¿è¡Œå¤æ‚åœºæ™¯æˆ–ç®€å•åœºæ™¯
    run_simple_scenario()
    #run_complex_scenario()
